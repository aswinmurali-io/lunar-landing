{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gym\n",
    "# ! pip3 install box2d-py\n",
    "# ! pip install stable-baselines[mpi]==2.10.0 box2d box2d-kengz\n",
    "# ! pip install 'ribs[all]' gym~=0.17.0 Box2D~=2.3.10 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(obs_size, n_actions)\n",
    "        # self.fc2 = nn.Linear(hidden_size, 128)\n",
    "        # self.fc3 = nn.Linear(128, n_actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(env,batch_size, t_max=1000):\n",
    "    \n",
    "    activation = nn.Softmax(dim=1)\n",
    "    batch_actions,batch_states, batch_rewards = [],[],[]\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        states,actions = [],[]\n",
    "        total_reward = 0\n",
    "        s = env.reset()\n",
    "        for t in range(t_max):\n",
    "            s_v = torch.FloatTensor([s])\n",
    "            act_probs_v = activation(net(s_v))\n",
    "            act_probs = act_probs_v.data.numpy()[0]\n",
    "            a = np.random.choice(len(act_probs), p=act_probs)\n",
    "            new_s, r, done, info = env.step(a)\n",
    "            states.append(s)\n",
    "            actions.append(a)\n",
    "            total_reward += r\n",
    "            s = new_s\n",
    "            if done:\n",
    "                batch_actions.append(actions)\n",
    "                batch_states.append(states)\n",
    "                batch_rewards.append(total_reward)\n",
    "                break\n",
    "    return batch_states, batch_actions, batch_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(states_batch,actions_batch,rewards_batch,percentile=50):\n",
    " \n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "\n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "\n",
    "\n",
    "    for i in range(len(rewards_batch)):\n",
    "        if rewards_batch[i] > reward_threshold:\n",
    "            for j in range(len(states_batch[i])):\n",
    "                elite_states.append(states_batch[i][j])\n",
    "                elite_actions.append(actions_batch[i][j])\n",
    "\n",
    "    return elite_states,elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=1.374, reward_mean=-231.4,reward_threshold=-105.3\n",
      "1: loss=1.369, reward_mean=-254.4,reward_threshold=-128.6\n",
      "2: loss=1.373, reward_mean=-243.0,reward_threshold=-104.2\n",
      "3: loss=1.378, reward_mean=-265.8,reward_threshold=-123.3\n",
      "4: loss=1.371, reward_mean=-230.1,reward_threshold=-104.6\n",
      "5: loss=1.373, reward_mean=-221.7,reward_threshold=-94.2\n",
      "6: loss=1.371, reward_mean=-255.9,reward_threshold=-123.3\n",
      "7: loss=1.368, reward_mean=-212.6,reward_threshold=-96.1\n",
      "8: loss=1.371, reward_mean=-218.0,reward_threshold=-100.9\n",
      "9: loss=1.382, reward_mean=-243.1,reward_threshold=-117.6\n",
      "10: loss=1.375, reward_mean=-221.5,reward_threshold=-100.8\n",
      "11: loss=1.378, reward_mean=-219.1,reward_threshold=-95.0\n",
      "12: loss=1.374, reward_mean=-244.9,reward_threshold=-107.5\n",
      "13: loss=1.366, reward_mean=-236.7,reward_threshold=-101.5\n",
      "14: loss=1.375, reward_mean=-217.0,reward_threshold=-101.0\n",
      "15: loss=1.376, reward_mean=-216.7,reward_threshold=-102.1\n",
      "16: loss=1.370, reward_mean=-210.4,reward_threshold=-108.5\n",
      "17: loss=1.375, reward_mean=-256.2,reward_threshold=-104.8\n",
      "18: loss=1.380, reward_mean=-217.3,reward_threshold=-109.7\n",
      "19: loss=1.369, reward_mean=-208.5,reward_threshold=-100.2\n",
      "20: loss=1.375, reward_mean=-212.9,reward_threshold=-101.3\n",
      "21: loss=1.377, reward_mean=-228.1,reward_threshold=-97.0\n",
      "22: loss=1.374, reward_mean=-232.4,reward_threshold=-100.4\n",
      "23: loss=1.380, reward_mean=-226.7,reward_threshold=-104.9\n",
      "24: loss=1.367, reward_mean=-221.0,reward_threshold=-111.8\n",
      "25: loss=1.371, reward_mean=-227.1,reward_threshold=-101.4\n",
      "26: loss=1.382, reward_mean=-210.7,reward_threshold=-108.3\n",
      "27: loss=1.375, reward_mean=-230.9,reward_threshold=-111.5\n",
      "28: loss=1.370, reward_mean=-193.0,reward_threshold=-98.9\n",
      "29: loss=1.370, reward_mean=-191.6,reward_threshold=-103.4\n",
      "30: loss=1.370, reward_mean=-199.4,reward_threshold=-96.0\n",
      "31: loss=1.376, reward_mean=-195.9,reward_threshold=-91.9\n",
      "32: loss=1.374, reward_mean=-193.9,reward_threshold=-92.8\n",
      "33: loss=1.372, reward_mean=-198.4,reward_threshold=-90.4\n",
      "34: loss=1.372, reward_mean=-186.3,reward_threshold=-87.6\n",
      "35: loss=1.368, reward_mean=-225.2,reward_threshold=-121.7\n",
      "36: loss=1.370, reward_mean=-176.3,reward_threshold=-94.9\n",
      "37: loss=1.372, reward_mean=-197.9,reward_threshold=-86.2\n",
      "38: loss=1.371, reward_mean=-183.3,reward_threshold=-97.8\n",
      "39: loss=1.382, reward_mean=-210.6,reward_threshold=-110.5\n",
      "40: loss=1.373, reward_mean=-187.2,reward_threshold=-88.7\n",
      "41: loss=1.377, reward_mean=-201.9,reward_threshold=-87.3\n",
      "42: loss=1.378, reward_mean=-193.6,reward_threshold=-101.9\n",
      "43: loss=1.373, reward_mean=-193.5,reward_threshold=-97.6\n",
      "44: loss=1.369, reward_mean=-170.0,reward_threshold=-89.6\n",
      "45: loss=1.376, reward_mean=-199.8,reward_threshold=-100.9\n",
      "46: loss=1.377, reward_mean=-189.7,reward_threshold=-96.3\n",
      "47: loss=1.370, reward_mean=-186.8,reward_threshold=-92.0\n",
      "48: loss=1.376, reward_mean=-172.2,reward_threshold=-87.2\n",
      "49: loss=1.377, reward_mean=-180.0,reward_threshold=-95.4\n",
      "50: loss=1.373, reward_mean=-175.6,reward_threshold=-92.5\n",
      "51: loss=1.377, reward_mean=-190.5,reward_threshold=-99.0\n",
      "52: loss=1.378, reward_mean=-184.8,reward_threshold=-91.0\n",
      "53: loss=1.373, reward_mean=-203.3,reward_threshold=-96.7\n",
      "54: loss=1.371, reward_mean=-174.8,reward_threshold=-95.4\n",
      "55: loss=1.374, reward_mean=-191.2,reward_threshold=-95.3\n",
      "56: loss=1.369, reward_mean=-172.7,reward_threshold=-82.8\n",
      "57: loss=1.374, reward_mean=-169.5,reward_threshold=-89.4\n",
      "58: loss=1.371, reward_mean=-180.7,reward_threshold=-85.1\n",
      "59: loss=1.368, reward_mean=-172.0,reward_threshold=-100.2\n",
      "60: loss=1.371, reward_mean=-189.1,reward_threshold=-84.9\n",
      "61: loss=1.372, reward_mean=-173.6,reward_threshold=-95.4\n",
      "62: loss=1.371, reward_mean=-169.1,reward_threshold=-84.9\n",
      "63: loss=1.370, reward_mean=-183.9,reward_threshold=-98.5\n",
      "64: loss=1.364, reward_mean=-146.0,reward_threshold=-74.4\n",
      "65: loss=1.370, reward_mean=-158.6,reward_threshold=-89.8\n",
      "66: loss=1.371, reward_mean=-180.3,reward_threshold=-88.6\n",
      "67: loss=1.371, reward_mean=-171.5,reward_threshold=-88.4\n",
      "68: loss=1.376, reward_mean=-169.7,reward_threshold=-88.4\n",
      "69: loss=1.375, reward_mean=-186.3,reward_threshold=-91.8\n",
      "70: loss=1.364, reward_mean=-145.0,reward_threshold=-87.8\n",
      "71: loss=1.367, reward_mean=-172.5,reward_threshold=-92.1\n",
      "72: loss=1.368, reward_mean=-166.1,reward_threshold=-94.8\n",
      "73: loss=1.377, reward_mean=-164.1,reward_threshold=-93.7\n",
      "74: loss=1.373, reward_mean=-165.9,reward_threshold=-87.8\n",
      "75: loss=1.361, reward_mean=-178.5,reward_threshold=-90.1\n",
      "76: loss=1.373, reward_mean=-162.1,reward_threshold=-86.4\n",
      "77: loss=1.367, reward_mean=-180.6,reward_threshold=-84.3\n",
      "78: loss=1.369, reward_mean=-154.9,reward_threshold=-85.1\n",
      "79: loss=1.373, reward_mean=-167.2,reward_threshold=-89.3\n",
      "80: loss=1.362, reward_mean=-155.6,reward_threshold=-84.9\n",
      "81: loss=1.360, reward_mean=-173.8,reward_threshold=-96.0\n",
      "82: loss=1.366, reward_mean=-153.8,reward_threshold=-89.3\n",
      "83: loss=1.367, reward_mean=-161.0,reward_threshold=-86.3\n",
      "84: loss=1.363, reward_mean=-155.8,reward_threshold=-94.4\n",
      "85: loss=1.364, reward_mean=-153.9,reward_threshold=-85.3\n",
      "86: loss=1.352, reward_mean=-155.9,reward_threshold=-82.4\n",
      "87: loss=1.370, reward_mean=-144.2,reward_threshold=-85.3\n",
      "88: loss=1.362, reward_mean=-161.0,reward_threshold=-89.6\n",
      "89: loss=1.366, reward_mean=-160.3,reward_threshold=-89.8\n",
      "90: loss=1.373, reward_mean=-158.0,reward_threshold=-85.2\n",
      "91: loss=1.359, reward_mean=-153.9,reward_threshold=-81.0\n",
      "92: loss=1.365, reward_mean=-146.2,reward_threshold=-76.3\n",
      "93: loss=1.368, reward_mean=-172.2,reward_threshold=-81.7\n",
      "94: loss=1.366, reward_mean=-152.5,reward_threshold=-88.8\n",
      "95: loss=1.363, reward_mean=-161.5,reward_threshold=-86.5\n",
      "96: loss=1.362, reward_mean=-141.0,reward_threshold=-77.6\n",
      "97: loss=1.364, reward_mean=-137.8,reward_threshold=-76.6\n",
      "98: loss=1.358, reward_mean=-151.6,reward_threshold=-81.8\n",
      "99: loss=1.368, reward_mean=-156.5,reward_threshold=-83.5\n",
      "100: loss=1.363, reward_mean=-147.0,reward_threshold=-75.5\n",
      "101: loss=1.361, reward_mean=-163.1,reward_threshold=-83.9\n",
      "102: loss=1.359, reward_mean=-146.8,reward_threshold=-69.0\n",
      "103: loss=1.364, reward_mean=-150.2,reward_threshold=-84.3\n",
      "104: loss=1.361, reward_mean=-154.2,reward_threshold=-80.6\n",
      "105: loss=1.358, reward_mean=-154.2,reward_threshold=-83.9\n",
      "106: loss=1.353, reward_mean=-158.7,reward_threshold=-85.5\n",
      "107: loss=1.361, reward_mean=-143.7,reward_threshold=-82.5\n",
      "108: loss=1.355, reward_mean=-151.6,reward_threshold=-81.7\n",
      "109: loss=1.355, reward_mean=-146.2,reward_threshold=-87.2\n",
      "110: loss=1.362, reward_mean=-148.4,reward_threshold=-86.1\n",
      "111: loss=1.366, reward_mean=-134.3,reward_threshold=-72.0\n",
      "112: loss=1.351, reward_mean=-163.3,reward_threshold=-84.1\n",
      "113: loss=1.355, reward_mean=-135.3,reward_threshold=-77.9\n",
      "114: loss=1.350, reward_mean=-158.9,reward_threshold=-81.5\n",
      "115: loss=1.359, reward_mean=-154.6,reward_threshold=-84.0\n",
      "116: loss=1.358, reward_mean=-141.7,reward_threshold=-75.9\n",
      "117: loss=1.354, reward_mean=-146.7,reward_threshold=-81.5\n",
      "118: loss=1.353, reward_mean=-138.0,reward_threshold=-78.2\n",
      "119: loss=1.355, reward_mean=-140.7,reward_threshold=-84.1\n",
      "120: loss=1.357, reward_mean=-159.8,reward_threshold=-97.9\n",
      "121: loss=1.357, reward_mean=-160.4,reward_threshold=-95.2\n",
      "122: loss=1.346, reward_mean=-154.8,reward_threshold=-81.8\n",
      "123: loss=1.353, reward_mean=-141.9,reward_threshold=-75.0\n",
      "124: loss=1.352, reward_mean=-136.9,reward_threshold=-79.6\n",
      "125: loss=1.353, reward_mean=-161.4,reward_threshold=-83.7\n",
      "126: loss=1.347, reward_mean=-143.7,reward_threshold=-79.2\n",
      "127: loss=1.342, reward_mean=-150.9,reward_threshold=-80.7\n",
      "128: loss=1.351, reward_mean=-146.8,reward_threshold=-78.4\n",
      "129: loss=1.352, reward_mean=-149.8,reward_threshold=-65.0\n",
      "130: loss=1.351, reward_mean=-141.2,reward_threshold=-76.9\n",
      "131: loss=1.349, reward_mean=-136.9,reward_threshold=-72.4\n",
      "132: loss=1.345, reward_mean=-140.1,reward_threshold=-79.8\n",
      "133: loss=1.349, reward_mean=-133.1,reward_threshold=-71.8\n",
      "134: loss=1.354, reward_mean=-140.5,reward_threshold=-80.8\n",
      "135: loss=1.352, reward_mean=-148.9,reward_threshold=-74.0\n",
      "136: loss=1.344, reward_mean=-150.5,reward_threshold=-75.9\n",
      "137: loss=1.335, reward_mean=-146.5,reward_threshold=-77.9\n",
      "138: loss=1.342, reward_mean=-137.8,reward_threshold=-67.5\n",
      "139: loss=1.344, reward_mean=-150.7,reward_threshold=-79.9\n",
      "140: loss=1.345, reward_mean=-132.9,reward_threshold=-70.3\n",
      "141: loss=1.341, reward_mean=-142.4,reward_threshold=-78.2\n",
      "142: loss=1.340, reward_mean=-131.0,reward_threshold=-69.1\n",
      "143: loss=1.340, reward_mean=-126.0,reward_threshold=-71.0\n",
      "144: loss=1.352, reward_mean=-132.5,reward_threshold=-67.6\n",
      "145: loss=1.341, reward_mean=-137.9,reward_threshold=-83.8\n",
      "146: loss=1.339, reward_mean=-136.2,reward_threshold=-75.0\n",
      "147: loss=1.347, reward_mean=-146.0,reward_threshold=-72.0\n",
      "148: loss=1.322, reward_mean=-140.9,reward_threshold=-83.7\n",
      "149: loss=1.343, reward_mean=-147.5,reward_threshold=-73.9\n",
      "150: loss=1.341, reward_mean=-140.7,reward_threshold=-78.6\n",
      "151: loss=1.344, reward_mean=-126.9,reward_threshold=-69.1\n",
      "152: loss=1.337, reward_mean=-127.2,reward_threshold=-70.2\n",
      "153: loss=1.339, reward_mean=-140.9,reward_threshold=-77.3\n",
      "154: loss=1.328, reward_mean=-130.7,reward_threshold=-78.0\n",
      "155: loss=1.342, reward_mean=-168.3,reward_threshold=-84.4\n",
      "156: loss=1.347, reward_mean=-146.7,reward_threshold=-85.7\n",
      "157: loss=1.339, reward_mean=-139.1,reward_threshold=-69.4\n",
      "158: loss=1.330, reward_mean=-138.6,reward_threshold=-79.3\n",
      "159: loss=1.334, reward_mean=-133.4,reward_threshold=-67.2\n",
      "160: loss=1.339, reward_mean=-134.2,reward_threshold=-78.4\n",
      "161: loss=1.335, reward_mean=-125.8,reward_threshold=-71.4\n",
      "162: loss=1.326, reward_mean=-126.5,reward_threshold=-68.2\n",
      "163: loss=1.339, reward_mean=-132.0,reward_threshold=-74.9\n",
      "164: loss=1.334, reward_mean=-134.8,reward_threshold=-74.4\n",
      "165: loss=1.329, reward_mean=-135.6,reward_threshold=-69.2\n",
      "166: loss=1.340, reward_mean=-153.2,reward_threshold=-88.4\n",
      "167: loss=1.338, reward_mean=-129.4,reward_threshold=-70.0\n",
      "168: loss=1.333, reward_mean=-127.0,reward_threshold=-66.0\n",
      "169: loss=1.331, reward_mean=-133.5,reward_threshold=-78.3\n",
      "170: loss=1.324, reward_mean=-125.0,reward_threshold=-69.6\n",
      "171: loss=1.326, reward_mean=-141.0,reward_threshold=-73.3\n",
      "172: loss=1.324, reward_mean=-124.8,reward_threshold=-64.7\n",
      "173: loss=1.337, reward_mean=-159.6,reward_threshold=-75.7\n",
      "174: loss=1.327, reward_mean=-126.0,reward_threshold=-68.7\n",
      "175: loss=1.334, reward_mean=-146.9,reward_threshold=-75.9\n",
      "176: loss=1.345, reward_mean=-127.8,reward_threshold=-71.1\n",
      "177: loss=1.342, reward_mean=-117.8,reward_threshold=-64.6\n",
      "178: loss=1.337, reward_mean=-121.6,reward_threshold=-75.6\n",
      "179: loss=1.331, reward_mean=-132.9,reward_threshold=-69.7\n",
      "180: loss=1.328, reward_mean=-133.3,reward_threshold=-77.5\n",
      "181: loss=1.328, reward_mean=-130.7,reward_threshold=-70.2\n",
      "182: loss=1.325, reward_mean=-124.3,reward_threshold=-69.1\n",
      "183: loss=1.326, reward_mean=-128.3,reward_threshold=-70.5\n",
      "184: loss=1.339, reward_mean=-124.5,reward_threshold=-61.5\n",
      "185: loss=1.340, reward_mean=-128.9,reward_threshold=-68.0\n",
      "186: loss=1.328, reward_mean=-134.2,reward_threshold=-68.8\n",
      "187: loss=1.338, reward_mean=-122.5,reward_threshold=-68.9\n",
      "188: loss=1.335, reward_mean=-127.1,reward_threshold=-64.7\n",
      "189: loss=1.330, reward_mean=-125.3,reward_threshold=-62.2\n",
      "190: loss=1.333, reward_mean=-121.3,reward_threshold=-65.7\n",
      "191: loss=1.330, reward_mean=-139.5,reward_threshold=-74.4\n",
      "192: loss=1.320, reward_mean=-125.9,reward_threshold=-60.7\n",
      "193: loss=1.326, reward_mean=-128.0,reward_threshold=-64.3\n",
      "194: loss=1.336, reward_mean=-131.5,reward_threshold=-76.9\n",
      "195: loss=1.320, reward_mean=-120.0,reward_threshold=-62.7\n",
      "196: loss=1.331, reward_mean=-123.8,reward_threshold=-65.3\n",
      "197: loss=1.323, reward_mean=-120.9,reward_threshold=-75.6\n",
      "198: loss=1.338, reward_mean=-124.3,reward_threshold=-57.4\n",
      "199: loss=1.325, reward_mean=-120.0,reward_threshold=-71.5\n",
      "200: loss=1.337, reward_mean=-126.0,reward_threshold=-70.6\n",
      "201: loss=1.334, reward_mean=-116.6,reward_threshold=-57.0\n",
      "202: loss=1.332, reward_mean=-121.3,reward_threshold=-61.3\n",
      "203: loss=1.333, reward_mean=-116.4,reward_threshold=-69.5\n",
      "204: loss=1.313, reward_mean=-118.4,reward_threshold=-66.4\n",
      "205: loss=1.320, reward_mean=-119.5,reward_threshold=-71.8\n",
      "206: loss=1.319, reward_mean=-125.5,reward_threshold=-65.6\n",
      "207: loss=1.334, reward_mean=-123.8,reward_threshold=-72.8\n",
      "208: loss=1.327, reward_mean=-123.6,reward_threshold=-63.4\n",
      "209: loss=1.325, reward_mean=-111.3,reward_threshold=-65.0\n",
      "210: loss=1.327, reward_mean=-115.7,reward_threshold=-64.2\n",
      "211: loss=1.325, reward_mean=-122.4,reward_threshold=-61.4\n",
      "212: loss=1.336, reward_mean=-113.0,reward_threshold=-70.8\n",
      "213: loss=1.320, reward_mean=-117.5,reward_threshold=-68.1\n",
      "214: loss=1.307, reward_mean=-114.7,reward_threshold=-67.0\n",
      "215: loss=1.320, reward_mean=-108.2,reward_threshold=-61.1\n",
      "216: loss=1.327, reward_mean=-122.3,reward_threshold=-70.7\n",
      "217: loss=1.318, reward_mean=-112.9,reward_threshold=-51.4\n",
      "218: loss=1.317, reward_mean=-124.9,reward_threshold=-60.8\n",
      "219: loss=1.330, reward_mean=-109.3,reward_threshold=-63.4\n",
      "220: loss=1.331, reward_mean=-119.8,reward_threshold=-71.8\n",
      "221: loss=1.316, reward_mean=-110.7,reward_threshold=-61.0\n",
      "222: loss=1.324, reward_mean=-117.2,reward_threshold=-59.6\n",
      "223: loss=1.332, reward_mean=-129.5,reward_threshold=-78.8\n",
      "224: loss=1.324, reward_mean=-113.3,reward_threshold=-63.8\n",
      "225: loss=1.316, reward_mean=-116.9,reward_threshold=-65.2\n",
      "226: loss=1.316, reward_mean=-116.6,reward_threshold=-73.0\n",
      "227: loss=1.314, reward_mean=-120.5,reward_threshold=-65.6\n",
      "228: loss=1.317, reward_mean=-115.4,reward_threshold=-72.0\n",
      "229: loss=1.318, reward_mean=-121.9,reward_threshold=-63.3\n",
      "230: loss=1.312, reward_mean=-115.4,reward_threshold=-49.3\n",
      "231: loss=1.306, reward_mean=-105.8,reward_threshold=-59.3\n",
      "232: loss=1.318, reward_mean=-102.5,reward_threshold=-58.2\n",
      "233: loss=1.314, reward_mean=-113.8,reward_threshold=-61.9\n",
      "234: loss=1.314, reward_mean=-112.9,reward_threshold=-56.7\n",
      "235: loss=1.314, reward_mean=-118.0,reward_threshold=-59.7\n",
      "236: loss=1.327, reward_mean=-104.3,reward_threshold=-54.7\n",
      "237: loss=1.308, reward_mean=-106.5,reward_threshold=-65.7\n",
      "238: loss=1.305, reward_mean=-107.6,reward_threshold=-52.0\n",
      "239: loss=1.312, reward_mean=-119.5,reward_threshold=-65.9\n",
      "240: loss=1.312, reward_mean=-112.0,reward_threshold=-65.1\n",
      "241: loss=1.319, reward_mean=-121.5,reward_threshold=-57.6\n",
      "242: loss=1.303, reward_mean=-107.5,reward_threshold=-54.8\n",
      "243: loss=1.326, reward_mean=-120.5,reward_threshold=-67.7\n",
      "244: loss=1.318, reward_mean=-120.2,reward_threshold=-70.4\n",
      "245: loss=1.296, reward_mean=-115.3,reward_threshold=-64.2\n",
      "246: loss=1.308, reward_mean=-114.9,reward_threshold=-56.1\n",
      "247: loss=1.313, reward_mean=-133.4,reward_threshold=-67.1\n",
      "248: loss=1.318, reward_mean=-109.4,reward_threshold=-55.2\n",
      "249: loss=1.305, reward_mean=-125.8,reward_threshold=-65.4\n",
      "250: loss=1.308, reward_mean=-101.7,reward_threshold=-54.0\n",
      "251: loss=1.295, reward_mean=-112.3,reward_threshold=-64.8\n",
      "252: loss=1.303, reward_mean=-117.7,reward_threshold=-63.4\n",
      "253: loss=1.318, reward_mean=-114.8,reward_threshold=-59.8\n",
      "254: loss=1.301, reward_mean=-105.2,reward_threshold=-60.7\n",
      "255: loss=1.307, reward_mean=-112.9,reward_threshold=-59.5\n",
      "256: loss=1.308, reward_mean=-108.8,reward_threshold=-53.0\n",
      "257: loss=1.313, reward_mean=-107.2,reward_threshold=-59.9\n",
      "258: loss=1.307, reward_mean=-114.8,reward_threshold=-61.9\n",
      "259: loss=1.297, reward_mean=-109.4,reward_threshold=-66.0\n",
      "260: loss=1.300, reward_mean=-120.9,reward_threshold=-62.6\n",
      "261: loss=1.297, reward_mean=-111.3,reward_threshold=-55.4\n",
      "262: loss=1.310, reward_mean=-106.6,reward_threshold=-53.5\n",
      "263: loss=1.298, reward_mean=-117.9,reward_threshold=-57.1\n",
      "264: loss=1.297, reward_mean=-112.9,reward_threshold=-56.9\n",
      "265: loss=1.302, reward_mean=-116.0,reward_threshold=-54.9\n",
      "266: loss=1.290, reward_mean=-104.5,reward_threshold=-52.5\n",
      "267: loss=1.304, reward_mean=-110.9,reward_threshold=-60.4\n",
      "268: loss=1.320, reward_mean=-102.8,reward_threshold=-54.3\n",
      "269: loss=1.309, reward_mean=-112.7,reward_threshold=-64.6\n",
      "270: loss=1.285, reward_mean=-113.8,reward_threshold=-61.7\n",
      "271: loss=1.299, reward_mean=-105.9,reward_threshold=-57.4\n",
      "272: loss=1.314, reward_mean=-100.6,reward_threshold=-48.3\n",
      "273: loss=1.308, reward_mean=-106.6,reward_threshold=-49.3\n",
      "274: loss=1.303, reward_mean=-123.3,reward_threshold=-59.7\n",
      "275: loss=1.291, reward_mean=-110.7,reward_threshold=-59.7\n",
      "276: loss=1.307, reward_mean=-110.5,reward_threshold=-50.4\n",
      "277: loss=1.287, reward_mean=-106.1,reward_threshold=-57.6\n",
      "278: loss=1.294, reward_mean=-108.3,reward_threshold=-55.2\n",
      "279: loss=1.305, reward_mean=-121.7,reward_threshold=-58.7\n",
      "280: loss=1.299, reward_mean=-107.1,reward_threshold=-51.0\n",
      "281: loss=1.305, reward_mean=-109.0,reward_threshold=-50.6\n",
      "282: loss=1.293, reward_mean=-106.3,reward_threshold=-57.4\n",
      "283: loss=1.274, reward_mean=-103.6,reward_threshold=-54.8\n",
      "284: loss=1.309, reward_mean=-116.7,reward_threshold=-61.5\n",
      "285: loss=1.302, reward_mean=-117.4,reward_threshold=-46.2\n",
      "286: loss=1.282, reward_mean=-110.2,reward_threshold=-47.2\n",
      "287: loss=1.283, reward_mean=-109.0,reward_threshold=-54.4\n",
      "288: loss=1.304, reward_mean=-119.3,reward_threshold=-50.5\n",
      "289: loss=1.279, reward_mean=-115.8,reward_threshold=-64.7\n",
      "290: loss=1.302, reward_mean=-112.1,reward_threshold=-53.5\n",
      "291: loss=1.267, reward_mean=-90.4,reward_threshold=-40.9\n",
      "292: loss=1.301, reward_mean=-116.4,reward_threshold=-59.8\n",
      "293: loss=1.297, reward_mean=-107.6,reward_threshold=-62.1\n",
      "294: loss=1.283, reward_mean=-96.3,reward_threshold=-45.3\n",
      "295: loss=1.294, reward_mean=-108.2,reward_threshold=-48.7\n",
      "296: loss=1.293, reward_mean=-101.3,reward_threshold=-44.0\n",
      "297: loss=1.286, reward_mean=-96.5,reward_threshold=-48.3\n",
      "298: loss=1.286, reward_mean=-112.4,reward_threshold=-48.2\n",
      "299: loss=1.295, reward_mean=-101.8,reward_threshold=-46.4\n",
      "300: loss=1.267, reward_mean=-125.1,reward_threshold=-53.4\n",
      "301: loss=1.282, reward_mean=-102.6,reward_threshold=-51.0\n",
      "302: loss=1.280, reward_mean=-113.0,reward_threshold=-57.4\n",
      "303: loss=1.277, reward_mean=-97.3,reward_threshold=-51.0\n",
      "304: loss=1.293, reward_mean=-107.3,reward_threshold=-54.8\n",
      "305: loss=1.286, reward_mean=-108.7,reward_threshold=-41.9\n",
      "306: loss=1.273, reward_mean=-104.4,reward_threshold=-53.1\n",
      "307: loss=1.293, reward_mean=-114.0,reward_threshold=-61.8\n",
      "308: loss=1.269, reward_mean=-99.5,reward_threshold=-44.5\n",
      "309: loss=1.296, reward_mean=-99.2,reward_threshold=-48.5\n",
      "310: loss=1.291, reward_mean=-102.8,reward_threshold=-43.7\n",
      "311: loss=1.302, reward_mean=-123.2,reward_threshold=-56.3\n",
      "312: loss=1.271, reward_mean=-105.3,reward_threshold=-51.4\n",
      "313: loss=1.285, reward_mean=-96.2,reward_threshold=-51.5\n",
      "314: loss=1.292, reward_mean=-107.8,reward_threshold=-55.4\n",
      "315: loss=1.290, reward_mean=-103.0,reward_threshold=-53.2\n",
      "316: loss=1.277, reward_mean=-108.4,reward_threshold=-56.0\n",
      "317: loss=1.267, reward_mean=-112.6,reward_threshold=-60.6\n",
      "318: loss=1.284, reward_mean=-102.5,reward_threshold=-44.9\n",
      "319: loss=1.265, reward_mean=-95.4,reward_threshold=-49.1\n",
      "320: loss=1.290, reward_mean=-103.2,reward_threshold=-47.0\n",
      "321: loss=1.261, reward_mean=-100.9,reward_threshold=-43.1\n",
      "322: loss=1.271, reward_mean=-110.0,reward_threshold=-57.4\n",
      "323: loss=1.242, reward_mean=-90.3,reward_threshold=-24.6\n",
      "324: loss=1.267, reward_mean=-99.1,reward_threshold=-48.0\n",
      "325: loss=1.303, reward_mean=-105.2,reward_threshold=-47.6\n",
      "326: loss=1.292, reward_mean=-100.0,reward_threshold=-39.8\n",
      "327: loss=1.284, reward_mean=-101.7,reward_threshold=-36.5\n",
      "328: loss=1.294, reward_mean=-97.9,reward_threshold=-39.2\n",
      "329: loss=1.276, reward_mean=-116.3,reward_threshold=-59.0\n",
      "330: loss=1.311, reward_mean=-113.0,reward_threshold=-46.9\n",
      "331: loss=1.258, reward_mean=-109.3,reward_threshold=-44.7\n",
      "332: loss=1.255, reward_mean=-109.1,reward_threshold=-47.0\n",
      "333: loss=1.281, reward_mean=-107.6,reward_threshold=-43.7\n",
      "334: loss=1.267, reward_mean=-97.1,reward_threshold=-35.9\n",
      "335: loss=1.277, reward_mean=-91.1,reward_threshold=-35.7\n",
      "336: loss=1.280, reward_mean=-84.9,reward_threshold=-35.9\n",
      "337: loss=1.294, reward_mean=-100.8,reward_threshold=-54.3\n",
      "338: loss=1.285, reward_mean=-109.4,reward_threshold=-47.0\n",
      "339: loss=1.252, reward_mean=-102.4,reward_threshold=-34.7\n",
      "340: loss=1.275, reward_mean=-97.6,reward_threshold=-40.7\n",
      "341: loss=1.268, reward_mean=-108.3,reward_threshold=-47.5\n",
      "342: loss=1.249, reward_mean=-98.2,reward_threshold=-43.0\n",
      "343: loss=1.286, reward_mean=-106.1,reward_threshold=-48.6\n",
      "344: loss=1.261, reward_mean=-84.9,reward_threshold=-44.1\n",
      "345: loss=1.283, reward_mean=-105.9,reward_threshold=-38.2\n",
      "346: loss=1.262, reward_mean=-97.3,reward_threshold=-38.5\n",
      "347: loss=1.277, reward_mean=-96.5,reward_threshold=-31.2\n",
      "348: loss=1.274, reward_mean=-91.4,reward_threshold=-38.7\n",
      "349: loss=1.261, reward_mean=-93.4,reward_threshold=-43.2\n",
      "350: loss=1.274, reward_mean=-94.7,reward_threshold=-38.0\n",
      "351: loss=1.266, reward_mean=-107.3,reward_threshold=-51.0\n",
      "352: loss=1.258, reward_mean=-97.1,reward_threshold=-48.4\n",
      "353: loss=1.284, reward_mean=-99.9,reward_threshold=-39.8\n",
      "354: loss=1.287, reward_mean=-93.2,reward_threshold=-45.2\n",
      "355: loss=1.245, reward_mean=-95.1,reward_threshold=-29.3\n",
      "356: loss=1.279, reward_mean=-103.4,reward_threshold=-37.8\n",
      "357: loss=1.280, reward_mean=-99.3,reward_threshold=-37.1\n",
      "358: loss=1.280, reward_mean=-91.2,reward_threshold=-32.5\n",
      "359: loss=1.267, reward_mean=-91.4,reward_threshold=-28.5\n",
      "360: loss=1.284, reward_mean=-93.8,reward_threshold=-41.5\n",
      "361: loss=1.290, reward_mean=-88.5,reward_threshold=-38.2\n",
      "362: loss=1.280, reward_mean=-87.7,reward_threshold=-36.0\n",
      "363: loss=1.238, reward_mean=-86.6,reward_threshold=-39.1\n",
      "364: loss=1.279, reward_mean=-96.1,reward_threshold=-40.7\n",
      "365: loss=1.268, reward_mean=-91.8,reward_threshold=-34.5\n",
      "366: loss=1.267, reward_mean=-95.8,reward_threshold=-39.0\n",
      "367: loss=1.288, reward_mean=-87.2,reward_threshold=-35.5\n",
      "368: loss=1.298, reward_mean=-105.7,reward_threshold=-43.5\n",
      "369: loss=1.261, reward_mean=-101.5,reward_threshold=-34.5\n",
      "370: loss=1.247, reward_mean=-95.0,reward_threshold=-29.8\n",
      "371: loss=1.262, reward_mean=-100.0,reward_threshold=-44.1\n",
      "372: loss=1.245, reward_mean=-100.0,reward_threshold=-35.9\n",
      "373: loss=1.231, reward_mean=-103.0,reward_threshold=-39.3\n",
      "374: loss=1.263, reward_mean=-97.5,reward_threshold=-29.6\n",
      "375: loss=1.273, reward_mean=-90.4,reward_threshold=-40.4\n",
      "376: loss=1.265, reward_mean=-94.0,reward_threshold=-27.8\n",
      "377: loss=1.249, reward_mean=-98.3,reward_threshold=-40.2\n",
      "378: loss=1.240, reward_mean=-93.7,reward_threshold=-29.1\n",
      "379: loss=1.284, reward_mean=-103.2,reward_threshold=-37.3\n",
      "380: loss=1.256, reward_mean=-78.9,reward_threshold=-24.6\n",
      "381: loss=1.235, reward_mean=-86.5,reward_threshold=-30.3\n",
      "382: loss=1.235, reward_mean=-93.7,reward_threshold=-30.9\n",
      "383: loss=1.278, reward_mean=-89.2,reward_threshold=-41.1\n",
      "384: loss=1.252, reward_mean=-105.6,reward_threshold=-48.2\n",
      "385: loss=1.265, reward_mean=-99.5,reward_threshold=-32.9\n",
      "386: loss=1.252, reward_mean=-96.0,reward_threshold=-33.8\n",
      "387: loss=1.283, reward_mean=-92.0,reward_threshold=-31.3\n",
      "388: loss=1.265, reward_mean=-85.8,reward_threshold=-32.9\n",
      "389: loss=1.253, reward_mean=-95.1,reward_threshold=-28.8\n",
      "390: loss=1.261, reward_mean=-88.0,reward_threshold=-28.4\n",
      "391: loss=1.222, reward_mean=-100.4,reward_threshold=-29.0\n",
      "392: loss=1.268, reward_mean=-82.0,reward_threshold=-17.2\n",
      "393: loss=1.254, reward_mean=-103.2,reward_threshold=-36.9\n",
      "394: loss=1.236, reward_mean=-101.1,reward_threshold=-35.2\n",
      "395: loss=1.263, reward_mean=-90.2,reward_threshold=-32.6\n",
      "396: loss=1.240, reward_mean=-81.4,reward_threshold=-24.5\n",
      "397: loss=1.232, reward_mean=-89.0,reward_threshold=-34.6\n",
      "398: loss=1.236, reward_mean=-75.9,reward_threshold=-23.7\n",
      "399: loss=1.273, reward_mean=-89.2,reward_threshold=-30.4\n",
      "400: loss=1.269, reward_mean=-87.6,reward_threshold=-23.7\n",
      "401: loss=1.282, reward_mean=-80.1,reward_threshold=-21.1\n",
      "402: loss=1.255, reward_mean=-85.5,reward_threshold=-30.2\n",
      "403: loss=1.250, reward_mean=-83.5,reward_threshold=-23.5\n",
      "404: loss=1.266, reward_mean=-96.3,reward_threshold=-33.3\n",
      "405: loss=1.256, reward_mean=-88.1,reward_threshold=-35.7\n",
      "406: loss=1.212, reward_mean=-84.6,reward_threshold=-28.7\n",
      "407: loss=1.227, reward_mean=-80.5,reward_threshold=-27.6\n",
      "408: loss=1.227, reward_mean=-77.4,reward_threshold=-21.7\n",
      "409: loss=1.220, reward_mean=-97.1,reward_threshold=-35.5\n",
      "410: loss=1.226, reward_mean=-99.3,reward_threshold=-49.0\n",
      "411: loss=1.262, reward_mean=-101.2,reward_threshold=-24.1\n",
      "412: loss=1.249, reward_mean=-76.4,reward_threshold=-19.5\n",
      "413: loss=1.236, reward_mean=-98.8,reward_threshold=-44.7\n",
      "414: loss=1.228, reward_mean=-110.1,reward_threshold=-47.1\n",
      "415: loss=1.260, reward_mean=-83.1,reward_threshold=-26.1\n",
      "416: loss=1.236, reward_mean=-84.7,reward_threshold=-28.6\n",
      "417: loss=1.208, reward_mean=-78.2,reward_threshold=-23.4\n",
      "418: loss=1.238, reward_mean=-88.5,reward_threshold=-27.6\n",
      "419: loss=1.234, reward_mean=-106.2,reward_threshold=-36.3\n",
      "420: loss=1.234, reward_mean=-68.6,reward_threshold=-14.5\n",
      "421: loss=1.240, reward_mean=-94.7,reward_threshold=-25.2\n",
      "422: loss=1.254, reward_mean=-74.4,reward_threshold=-11.5\n",
      "423: loss=1.207, reward_mean=-97.3,reward_threshold=-34.0\n",
      "424: loss=1.265, reward_mean=-85.2,reward_threshold=-22.9\n",
      "425: loss=1.253, reward_mean=-72.6,reward_threshold=-17.6\n",
      "426: loss=1.241, reward_mean=-78.3,reward_threshold=-21.7\n",
      "427: loss=1.236, reward_mean=-80.1,reward_threshold=-21.1\n",
      "428: loss=1.255, reward_mean=-84.1,reward_threshold=-36.7\n",
      "429: loss=1.270, reward_mean=-91.1,reward_threshold=-24.7\n",
      "430: loss=1.238, reward_mean=-78.6,reward_threshold=-18.2\n",
      "431: loss=1.254, reward_mean=-82.3,reward_threshold=-22.6\n",
      "432: loss=1.223, reward_mean=-95.8,reward_threshold=-35.9\n",
      "433: loss=1.229, reward_mean=-95.8,reward_threshold=-35.1\n",
      "434: loss=1.236, reward_mean=-75.7,reward_threshold=-27.0\n",
      "435: loss=1.264, reward_mean=-78.8,reward_threshold=-17.9\n",
      "436: loss=1.250, reward_mean=-75.0,reward_threshold=-16.2\n",
      "437: loss=1.252, reward_mean=-87.4,reward_threshold=-19.3\n",
      "438: loss=1.224, reward_mean=-78.9,reward_threshold=-16.5\n",
      "439: loss=1.208, reward_mean=-91.1,reward_threshold=-35.6\n",
      "440: loss=1.239, reward_mean=-89.9,reward_threshold=-34.5\n",
      "441: loss=1.280, reward_mean=-100.4,reward_threshold=-45.0\n",
      "442: loss=1.221, reward_mean=-83.5,reward_threshold=-16.6\n",
      "443: loss=1.219, reward_mean=-93.0,reward_threshold=-35.8\n",
      "444: loss=1.235, reward_mean=-75.8,reward_threshold=-21.4\n",
      "445: loss=1.208, reward_mean=-87.7,reward_threshold=-28.5\n",
      "446: loss=1.218, reward_mean=-81.8,reward_threshold=-28.6\n",
      "447: loss=1.248, reward_mean=-74.3,reward_threshold=-17.9\n",
      "448: loss=1.240, reward_mean=-91.6,reward_threshold=-36.3\n",
      "449: loss=1.223, reward_mean=-69.6,reward_threshold=-16.3\n",
      "450: loss=1.238, reward_mean=-82.2,reward_threshold=-21.2\n",
      "451: loss=1.207, reward_mean=-91.3,reward_threshold=-24.4\n",
      "452: loss=1.276, reward_mean=-83.7,reward_threshold=-13.9\n",
      "453: loss=1.270, reward_mean=-74.5,reward_threshold=-18.0\n",
      "454: loss=1.238, reward_mean=-92.7,reward_threshold=-22.7\n",
      "455: loss=1.215, reward_mean=-83.8,reward_threshold=-25.0\n",
      "456: loss=1.264, reward_mean=-75.0,reward_threshold=-22.3\n",
      "457: loss=1.224, reward_mean=-80.1,reward_threshold=-20.9\n",
      "458: loss=1.257, reward_mean=-82.7,reward_threshold=-27.8\n",
      "459: loss=1.241, reward_mean=-63.1,reward_threshold=-22.4\n",
      "460: loss=1.273, reward_mean=-73.1,reward_threshold=-10.3\n",
      "461: loss=1.239, reward_mean=-83.4,reward_threshold=-19.1\n",
      "462: loss=1.246, reward_mean=-74.8,reward_threshold=-24.8\n",
      "463: loss=1.233, reward_mean=-78.8,reward_threshold=-20.2\n",
      "464: loss=1.272, reward_mean=-73.8,reward_threshold=-16.7\n",
      "465: loss=1.202, reward_mean=-72.3,reward_threshold=-16.2\n",
      "466: loss=1.244, reward_mean=-75.1,reward_threshold=-18.6\n",
      "467: loss=1.226, reward_mean=-83.5,reward_threshold=-30.4\n",
      "468: loss=1.245, reward_mean=-81.5,reward_threshold=-27.4\n",
      "469: loss=1.251, reward_mean=-84.0,reward_threshold=-20.8\n",
      "470: loss=1.262, reward_mean=-78.6,reward_threshold=-19.4\n",
      "471: loss=1.253, reward_mean=-66.4,reward_threshold=-13.1\n",
      "472: loss=1.234, reward_mean=-77.6,reward_threshold=-19.0\n",
      "473: loss=1.245, reward_mean=-74.4,reward_threshold=-25.0\n",
      "474: loss=1.228, reward_mean=-71.8,reward_threshold=-17.6\n",
      "475: loss=1.254, reward_mean=-72.7,reward_threshold=-24.0\n",
      "476: loss=1.252, reward_mean=-75.8,reward_threshold=-19.9\n",
      "477: loss=1.250, reward_mean=-70.3,reward_threshold=-12.1\n",
      "478: loss=1.224, reward_mean=-70.2,reward_threshold=-14.9\n",
      "479: loss=1.255, reward_mean=-66.6,reward_threshold=-11.3\n",
      "480: loss=1.222, reward_mean=-68.3,reward_threshold=-20.0\n",
      "481: loss=1.241, reward_mean=-70.8,reward_threshold=-21.3\n",
      "482: loss=1.232, reward_mean=-73.8,reward_threshold=-20.1\n",
      "483: loss=1.226, reward_mean=-90.2,reward_threshold=-19.4\n",
      "484: loss=1.249, reward_mean=-74.7,reward_threshold=-22.5\n",
      "485: loss=1.211, reward_mean=-70.1,reward_threshold=-13.5\n",
      "486: loss=1.260, reward_mean=-70.2,reward_threshold=-14.0\n",
      "487: loss=1.219, reward_mean=-77.8,reward_threshold=-12.7\n",
      "488: loss=1.224, reward_mean=-76.1,reward_threshold=-12.5\n",
      "489: loss=1.242, reward_mean=-64.6,reward_threshold=-15.2\n",
      "490: loss=1.212, reward_mean=-58.9,reward_threshold=-5.2\n",
      "491: loss=1.249, reward_mean=-76.6,reward_threshold=-19.8\n",
      "492: loss=1.232, reward_mean=-73.8,reward_threshold=-27.1\n",
      "493: loss=1.233, reward_mean=-88.6,reward_threshold=-26.0\n",
      "494: loss=1.242, reward_mean=-80.4,reward_threshold=-20.2\n",
      "495: loss=1.247, reward_mean=-67.2,reward_threshold=-17.9\n",
      "496: loss=1.271, reward_mean=-74.3,reward_threshold=-13.7\n",
      "497: loss=1.243, reward_mean=-67.6,reward_threshold=-6.6\n",
      "498: loss=1.253, reward_mean=-86.7,reward_threshold=-21.6\n",
      "499: loss=1.210, reward_mean=-60.5,reward_threshold=-15.2\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "session_size = 500\n",
    "percentile = 80\n",
    "hidden_size = 200\n",
    "learning_rate = 0.0025\n",
    "completion_score = 200\n",
    "n_states = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "#neural network\n",
    "net = Net(n_states, hidden_size, n_actions)\n",
    "#loss function\n",
    "objective = nn.CrossEntropyLoss()\n",
    "#optimisation function\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=learning_rate)\n",
    "for i in range(session_size):\n",
    "    #generate new sessions\n",
    "    batch_states,batch_actions,batch_rewards = generate_batch(env, batch_size, t_max=5000)\n",
    "    elite_states, elite_actions = filter_batch(batch_states,batch_actions,batch_rewards,percentile)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    tensor_states = torch.FloatTensor(elite_states)\n",
    "    tensor_actions = torch.LongTensor(elite_actions)\n",
    "    action_scores_v = net(tensor_states)\n",
    "    loss_v = objective(action_scores_v, tensor_actions)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    #show results\n",
    "    mean_reward, threshold = np.mean(batch_rewards),np.percentile(batch_rewards, percentile)\n",
    "    print(\"%d: loss=%.3f, reward_mean=%.1f,reward_threshold=%.1f\" % (i, loss_v.item(), mean_reward, threshold))\n",
    "    \n",
    "    #check if \n",
    "    if np.mean(batch_rewards)> completion_score:\n",
    "        print(\"Environment has been successfullly completed!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/gym/wrappers/monitor.py:31: UserWarning: The Monitor wrapper is being deprecated in favor of gym.wrappers.RecordVideo and gym.wrappers.RecordEpisodeStatistics (see https://github.com/openai/gym/issues/2297)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6t/fjr9gh2x3kzfp_x8d04mv8gm0000gn/T/ipykernel_46353/2918858505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# env = gym.wrappers.Monitor(gym.make(\"LunarLander-v2\"), directory=\"videos\", force=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"videos\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6t/fjr9gh2x3kzfp_x8d04mv8gm0000gn/T/ipykernel_46353/2351948936.py\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(env, batch_size, t_max)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0ms_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mact_probs_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mact_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_probs_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gym.wrappers\n",
    "# env = gym.wrappers.Monitor(gym.make(\"LunarLander-v2\"), directory=\"videos\", force=True)\n",
    "env = gym.wrappers.Monitor(env,directory=\"videos3\", force=False)\n",
    "generate_batch(env, 1, t_max=500)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
